#!/usr/bin/env python3
"""
Script de test pour simuler et vÃ©rifier la correction du problÃ¨me 
de statut figÃ© dans le sous-menu "Chemins & Dossiers".

Ce script simule l'initialisation du ViewModel et vÃ©rifie que
les mises Ã  jour de statut sont correctement implÃ©mentÃ©es.
"""

import os
import re
import json
import subprocess
from datetime import datetime

def analyze_dispatcher_usage():
    """Analyse l'utilisation du Dispatcher dans le ViewModel"""
    viewmodel_path = r"src\FNEV4.Presentation\ViewModels\Configuration\CheminsDossiersConfigViewModel.cs"
    
    if not os.path.exists(viewmodel_path):
        return {"error": "Fichier ViewModel non trouvÃ©"}
    
    with open(viewmodel_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Recherche des patterns critiques
    patterns = {
        "correct_initial_message": r'globalStatusMessage\s*=\s*"Initialisation en cours..."',
        "immediate_initialization": r'_\s*=\s*InitializeStatusImmediatelyAsync\(\);',
        "dispatcher_in_update_global": r'System\.Windows\.Application\.Current\.Dispatcher\.InvokeAsync\(\(\)\s*=>\s*{[^}]*GlobalStatusMessage\s*=',
        "configured_folders_count_update": r'ConfiguredFoldersCount\s*=\s*finalCount',
        "status_message_variations": [
            r'"ğŸ”§\s*\{\w+\}/5\s*dossiers\s*configurÃ©s"',
            r'"âœ…\s*Tous\s*les\s*dossiers\s*sont\s*configurÃ©s"',
            r'"âŒ.*dossier\(s\)\s*avec\s*erreurs"',
            r'"âš ï¸.*dossier\(s\)\s*avec\s*avertissements"'
        ]
    }
    
    results = {}
    
    # Test des patterns principaux
    for pattern_name, pattern in patterns.items():
        if pattern_name == "status_message_variations":
            results[pattern_name] = []
            for i, variation in enumerate(pattern):
                matches = re.findall(variation, content, re.MULTILINE | re.DOTALL)
                results[pattern_name].append({
                    "variation": i + 1,
                    "found": len(matches) > 0,
                    "count": len(matches)
                })
        else:
            matches = re.findall(pattern, content, re.MULTILINE | re.DOTALL)
            results[pattern_name] = {
                "found": len(matches) > 0,
                "count": len(matches)
            }
    
    return results

def test_initialization_flow():
    """Teste le flux d'initialisation"""
    viewmodel_path = r"src\FNEV4.Presentation\ViewModels\Configuration\CheminsDossiersConfigViewModel.cs"
    
    if not os.path.exists(viewmodel_path):
        return {"error": "Fichier ViewModel non trouvÃ©"}
    
    with open(viewmodel_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Recherche du constructeur et de l'initialisation
    constructor_pattern = r'public\s+CheminsDossiersConfigViewModel\([^)]*\)\s*{([^}]+)}'
    constructor_match = re.search(constructor_pattern, content, re.DOTALL)
    
    if not constructor_match:
        return {"error": "Constructeur non trouvÃ©"}
    
    constructor_content = constructor_match.group(1)
    
    # VÃ©rifications dans le constructeur
    constructor_checks = {
        "calls_initialize_immediately": "InitializeStatusImmediatelyAsync" in constructor_content,
        "fire_and_forget_pattern": "_ =" in constructor_content,
        "no_await_in_constructor": "await" not in constructor_content
    }
    
    # Recherche de la mÃ©thode InitializeStatusImmediatelyAsync
    init_pattern = r'private\s+async\s+Task\s+InitializeStatusImmediatelyAsync\(\)\s*{([^}]+(?:{[^}]*}[^}]*)*)}'
    init_match = re.search(init_pattern, content, re.DOTALL)
    
    init_method_checks = {}
    if init_match:
        init_content = init_match.group(1)
        init_method_checks = {
            "has_dispatcher_invoke": "Dispatcher.InvokeAsync" in init_content,
            "sets_initial_message": "VÃ©rification des dossiers" in init_content,
            "calls_update_all_status": "UpdateAllStatusAsync" in init_content,
            "has_error_handling": "catch" in init_content
        }
    else:
        init_method_checks = {"error": "MÃ©thode InitializeStatusImmediatelyAsync non trouvÃ©e"}
    
    return {
        "constructor_checks": constructor_checks,
        "init_method_checks": init_method_checks
    }

def verify_status_update_logic():
    """VÃ©rifie la logique de mise Ã  jour des statuts"""
    viewmodel_path = r"src\FNEV4.Presentation\ViewModels\Configuration\CheminsDossiersConfigViewModel.cs"
    
    if not os.path.exists(viewmodel_path):
        return {"error": "Fichier ViewModel non trouvÃ©"}
    
    with open(viewmodel_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Recherche de la mÃ©thode UpdateGlobalStatusAsync
    update_global_pattern = r'private\s+Task\s+UpdateGlobalStatusAsync\(\)\s*{([^}]+(?:{[^}]*}[^}]*)*)}'
    update_match = re.search(update_global_pattern, content, re.DOTALL)
    
    if not update_match:
        return {"error": "MÃ©thode UpdateGlobalStatusAsync non trouvÃ©e"}
    
    update_content = update_match.group(1)
    
    # VÃ©rifications de la logique
    logic_checks = {
        "calculates_valid_count": "validCount" in update_content,
        "calculates_warning_count": "warningCount" in update_content,
        "calculates_invalid_count": "invalidCount" in update_content,
        "has_status_logic": "if (invalidCount > 0)" in update_content,
        "uses_final_variables": "finalMessage" in update_content and "finalIcon" in update_content,
        "updates_in_dispatcher": "Dispatcher.InvokeAsync" in update_content,
        "updates_configured_count": "ConfiguredFoldersCount = finalCount" in update_content,
        "no_configuration_en_cours": "Configuration en cours" not in update_content,
        "has_configured_message": "dossiers configurÃ©s" in update_content
    }
    
    # Compter les diffÃ©rents Ã©tats de messages
    message_states = {
        "error_message": update_content.count("âŒ"),
        "warning_message": update_content.count("âš ï¸"),
        "success_message": update_content.count("âœ…"),
        "progress_message": update_content.count("ğŸ”§")
    }
    
    return {
        "logic_checks": logic_checks,
        "message_states": message_states
    }

def simulate_runtime_test():
    """Simule un test d'exÃ©cution"""
    # Tentative de compilation
    try:
        result = subprocess.run(
            ["dotnet", "build", "FNEV4.sln", "--configuration", "Release", "--verbosity", "quiet"],
            capture_output=True,
            text=True,
            timeout=30
        )
        
        compilation_success = result.returncode == 0
        compilation_errors = result.stderr if result.stderr else "Aucune erreur"
        
        # Check des DLL gÃ©nÃ©rÃ©es
        dll_files = [
            r"src\FNEV4.Presentation\bin\Release\net8.0-windows\FNEV4.Presentation.dll",
            r"src\FNEV4.Core\bin\Release\net8.0\FNEV4.Core.dll",
            r"src\FNEV4.Application\bin\Release\net8.0\FNEV4.Application.dll"
        ]
        
        dll_status = {}
        for dll in dll_files:
            dll_status[os.path.basename(dll)] = os.path.exists(dll)
        
        return {
            "compilation_success": compilation_success,
            "compilation_errors": compilation_errors,
            "dll_status": dll_status
        }
        
    except subprocess.TimeoutExpired:
        return {"error": "Timeout lors de la compilation"}
    except Exception as e:
        return {"error": f"Erreur lors de la compilation: {str(e)}"}

def create_comprehensive_report():
    """CrÃ©e un rapport complet"""
    report = {
        "timestamp": datetime.now().isoformat(),
        "test_type": "Test Complet - Correction Statut FigÃ©",
        "dispatcher_analysis": analyze_dispatcher_usage(),
        "initialization_flow": test_initialization_flow(),
        "status_update_logic": verify_status_update_logic(),
        "runtime_simulation": simulate_runtime_test()
    }
    
    # Calcul du score global
    scores = []
    
    # Score du Dispatcher
    dispatcher = report["dispatcher_analysis"]
    if "error" not in dispatcher:
        dispatcher_score = 0
        total_dispatcher_checks = 0
        
        for key, value in dispatcher.items():
            if key == "status_message_variations":
                for variation in value:
                    total_dispatcher_checks += 1
                    if variation["found"]:
                        dispatcher_score += 1
            elif isinstance(value, dict) and "found" in value:
                total_dispatcher_checks += 1
                if value["found"]:
                    dispatcher_score += 1
        
        if total_dispatcher_checks > 0:
            scores.append((dispatcher_score / total_dispatcher_checks) * 100)
    
    # Score d'initialisation
    init = report["initialization_flow"]
    if "error" not in init:
        init_score = 0
        total_init_checks = 0
        
        for check_group in ["constructor_checks", "init_method_checks"]:
            if check_group in init and "error" not in init[check_group]:
                for check, result in init[check_group].items():
                    total_init_checks += 1
                    if result:
                        init_score += 1
        
        if total_init_checks > 0:
            scores.append((init_score / total_init_checks) * 100)
    
    # Score de logique de mise Ã  jour
    update = report["status_update_logic"]
    if "error" not in update and "logic_checks" in update:
        update_score = 0
        total_update_checks = len(update["logic_checks"])
        
        for check, result in update["logic_checks"].items():
            if result:
                update_score += 1
        
        if total_update_checks > 0:
            scores.append((update_score / total_update_checks) * 100)
    
    # Score global
    if scores:
        report["global_score"] = sum(scores) / len(scores)
    else:
        report["global_score"] = 0
    
    return report

def display_comprehensive_results(report):
    """Affiche les rÃ©sultats complets"""
    print("=" * 80)
    print("RAPPORT COMPLET - TEST CORRECTION STATUT FIGÃ‰")
    print("=" * 80)
    print(f"Timestamp: {report['timestamp']}")
    print(f"ğŸ¯ Score Global: {report['global_score']:.1f}%")
    print()
    
    # Analyse du Dispatcher
    print("ğŸ§µ ANALYSE DU DISPATCHER:")
    print("-" * 40)
    dispatcher = report["dispatcher_analysis"]
    if "error" in dispatcher:
        print(f"âŒ Erreur: {dispatcher['error']}")
    else:
        for key, value in dispatcher.items():
            if key == "status_message_variations":
                print("ğŸ“ Variations de messages de statut:")
                for variation in value:
                    icon = "âœ…" if variation["found"] else "âŒ"
                    print(f"  {icon} Variation {variation['variation']}: {variation['found']}")
            elif isinstance(value, dict) and "found" in value:
                icon = "âœ…" if value["found"] else "âŒ"
                print(f"{icon} {key.replace('_', ' ').title()}: {value['found']}")
    
    print()
    
    # Flux d'initialisation
    print("ğŸš€ FLUX D'INITIALISATION:")
    print("-" * 40)
    init = report["initialization_flow"]
    if "error" in init:
        print(f"âŒ Erreur: {init['error']}")
    else:
        print("Constructeur:")
        for check, result in init.get("constructor_checks", {}).items():
            icon = "âœ…" if result else "âŒ"
            print(f"  {icon} {check.replace('_', ' ').title()}: {result}")
        
        print("MÃ©thode d'initialisation:")
        init_checks = init.get("init_method_checks", {})
        if "error" in init_checks:
            print(f"  âŒ {init_checks['error']}")
        else:
            for check, result in init_checks.items():
                icon = "âœ…" if result else "âŒ"
                print(f"  {icon} {check.replace('_', ' ').title()}: {result}")
    
    print()
    
    # Logique de mise Ã  jour
    print("ğŸ”„ LOGIQUE DE MISE Ã€ JOUR:")
    print("-" * 40)
    update = report["status_update_logic"]
    if "error" in update:
        print(f"âŒ Erreur: {update['error']}")
    else:
        logic_checks = update.get("logic_checks", {})
        for check, result in logic_checks.items():
            icon = "âœ…" if result else "âŒ"
            print(f"{icon} {check.replace('_', ' ').title()}: {result}")
        
        message_states = update.get("message_states", {})
        if message_states:
            print("\nğŸ“Š Ã‰tats des messages:")
            for state, count in message_states.items():
                print(f"  {state.replace('_', ' ').title()}: {count}")
    
    print()
    
    # Simulation d'exÃ©cution
    print("âš™ï¸ SIMULATION D'EXÃ‰CUTION:")
    print("-" * 40)
    runtime = report["runtime_simulation"]
    if "error" in runtime:
        print(f"âŒ Erreur: {runtime['error']}")
    else:
        icon = "âœ…" if runtime.get("compilation_success", False) else "âŒ"
        print(f"{icon} Compilation: {'RÃ©ussie' if runtime.get('compilation_success', False) else 'Ã‰chouÃ©e'}")
        
        if not runtime.get("compilation_success", False):
            print(f"Erreurs: {runtime.get('compilation_errors', 'Inconnues')}")
        
        dll_status = runtime.get("dll_status", {})
        if dll_status:
            print("DLL gÃ©nÃ©rÃ©es:")
            for dll, exists in dll_status.items():
                icon = "âœ…" if exists else "âŒ"
                print(f"  {icon} {dll}: {'PrÃ©sent' if exists else 'Manquant'}")
    
    print()
    
    # Conclusion
    print("ğŸ¯ CONCLUSION:")
    print("-" * 40)
    score = report['global_score']
    if score >= 95:
        print("ğŸš€ EXCELLENT - Le problÃ¨me de statut figÃ© est complÃ¨tement corrigÃ©!")
        status = "RÃ‰SOLU"
    elif score >= 85:
        print("âœ… TRÃˆS BON - La correction devrait fonctionner correctement")
        status = "LARGEMENT CORRIGÃ‰"
    elif score >= 75:
        print("âš ï¸ BON - Quelques amÃ©liorations mineures peuvent Ãªtre nÃ©cessaires")
        status = "MAJORITAIREMENT CORRIGÃ‰"
    else:
        print("âŒ Des corrections supplÃ©mentaires sont nÃ©cessaires")
        status = "PARTIELLEMENT CORRIGÃ‰"
    
    print(f"Status: {status}")
    
    print("\nğŸ“ RECOMMANDATIONS:")
    print("-" * 40)
    if score >= 90:
        print("1. âœ… Lancez l'application - le statut ne devrait plus Ãªtre figÃ©")
        print("2. âœ… Le message devrait passer de 'Initialisation en cours...' Ã  'ğŸ”§ X/5 dossiers configurÃ©s'")
        print("3. âœ… Surveillez les logs pour confirmer le bon fonctionnement")
    else:
        print("1. VÃ©rifiez les Ã©lÃ©ments marquÃ©s âŒ ci-dessus")
        print("2. Testez l'application avec prudence")
        print("3. Consultez les logs pour d'Ã©ventuelles erreurs")

def main():
    """Fonction principale"""
    print("Test complet de la correction du statut figÃ©...")
    print("Analyse approfondie en cours...\n")
    
    # Changer vers le rÃ©pertoire du projet
    if os.path.exists("FNEV4.sln"):
        os.chdir(".")
    else:
        print("âŒ Impossible de trouver le projet FNEV4")
        return
    
    # CrÃ©er le rapport complet
    report = create_comprehensive_report()
    
    # Afficher les rÃ©sultats
    display_comprehensive_results(report)
    
    # Sauvegarder le rapport
    with open("test_complet_correction_statut.json", 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ Rapport complet sauvegardÃ© dans: test_complet_correction_statut.json")

if __name__ == "__main__":
    main()
